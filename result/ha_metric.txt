============== Train Info ==============
Dataset number: 3
Model: HA
Train: 2016-09-01T00:00:00+00:00 --> 2016-11-30T00:00:00+00:00
Val: 2016-12-01T00:00:00+00:00 --> 2016-12-31T00:00:00+00:00
Test: 2017-01-01T00:00:00+00:00 --> 2017-01-31T00:00:00+00:00
City number: 13
Use metero: ['2m_temperature', 'boundary_layer_height', 'k_index', 'relative_humidity+950', 'surface_pressure', 'total_precipitation', 'u_component_of_wind+950', 'v_component_of_wind+950']
batch_size: 32
epochs: 50
hist_len: 8
pred_len: 8
cycle_len: 8
weight_decay: 1e-05
early_stop: 10
lr: 0.001
========================================
HA(
  (fc_in): Linear(in_features=13, out_features=32, bias=True)
  (fc_out): Linear(in_features=32, out_features=1, bias=True)
  (lstm_cell): LSTMCell(
    (x2h): Linear(in_features=32, out_features=128, bias=True)
    (h2h): Linear(in_features=32, out_features=128, bias=True)
  )
)---------------------------------------
train_loss | mean: 0.2668 std: 0.0058
val_loss   | mean: 0.3107 std: 0.0070
test_loss  | mean: 0.4233 std: 0.0098
RMSE       | mean: 38.3333 std: 0.5417
MAE        | mean: 22.8187 std: 0.3897
CSI        | mean: 0.8801 std: 0.0053
POD        | mean: 0.9685 std: 0.0039
FAR        | mean: 0.0939 std: 0.0060
MAPE        | mean: 0.3307 std: 0.0156

=================== Model Info ===================
model params: 8929
GPU memory usage during training: 10.8296GB
GPU memory usage during testing: 0.1426GB
Training time: 88.4041s
Inference time: 0.2674s
Model file path: E:/jupyter/match/create/data/results\8_8\3\HA\20250331222341\09\model.pth
